# Estudo de Caso Tarea ‚Äî Extra√ß√£o, Classifica√ß√£o, Busca e Chat sobre PDFs

Aplica√ß√£o **local** para:
1) Ler e extrair texto de PDFs  
2) Classificar automaticamente por tipo de documento (Lei, Portaria, Resolu√ß√£o, Outros)  
3) Realizar **busca sem√¢ntica** em linguagem natural  
4) Interagir com um **LLM local** para d√∫vidas/resumos usando o contexto dos PDFs


## üß© Stack
- **Extra√ß√£o**: [PyMuPDF]
- **Classifica√ß√£o**: regras + (opcional) modelo TF-IDF `scikit-learn`
- **Busca**: `sentence-transformers` (**all-MiniLM-L6-v2**) + `FAISS`
- **UI**: `Streamlit`
- **LLM**: `gpt4all` **OU** `llama-cpp-python` (se instalado)

> Se voc√™ n√£o tiver um LLM local, o chat ainda funciona em **modo extrativo** (concatena trechos recuperados e gera uma resposta objetiva).


## üì¶ Instala√ß√£o

> Requer Python 3.10+

```bash
python3 -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requerimentos.txt
```

### Modelos
- O modelo de embeddings **all-MiniLM-L6-v2** ser√° baixado automaticamente
  (se preferir, baixe antes e aponte via vari√°vel `SENTENCE_TRANSFORMERS_HOME`).

### LLM local (opcional)
Escolha **um**:
- `pip install gpt4all`
  - Baixe um modelo `.gguf` pelo app do gpt4all e aponte `GPT4ALL_MODEL_PATH=/caminho/modelo.gguf`
- `pip install llama-cpp-python`
  - Aponte `LLAMA_MODEL_PATH=/caminho/modelo.gguf`

## üìÅ Estrutura

```
case_estudo_pdf_app/
  src/
    extract_text.py
    classify.py
    index_search.py
    chat_llm.py
  data/
    pdfs/  # coloque aqui seus PDFs (Lei_*, Portaria_*, Resolu√ß√£o_* ...)
  app.py       # UI Streamlit
  build_index.py
  search_cli.py
  requirements.txt
  README.md
```

## ‚ñ∂Ô∏è Como usar

1. **Coloque os PDFs** em `dados/`
2. **Crie/atualize o √≠ndice** (texto, classifica√ß√£o, embeddings):
```bash
python build_index.py
```
3. **Rodar a UI**:
```bash
streamlit run app.py
```
4. **Buscar pelo CLI (opcional)**:
```bash
python search_cli.py "Quais s√£o os princ√≠pios da educa√ß√£o segundo a LDB?"
```

## ‚öôÔ∏è Vari√°veis de ambiente (opcional)
- `EMBEDDING_MODEL_NAME` (default: `sentence-transformers/all-MiniLM-L6-v2`)
- `GPT4ALL_MODEL_PATH` (se usar gpt4all)
- `LLAMA_MODEL_PATH` (se usar llama-cpp)
- `INDEX_DIR` (default: `.index`)

## üß™ Notas
- A classifica√ß√£o inicial usa **regras simples** (r√°pidas e transparentes). Se quiser, ative o modo ML no `classify.py`.
- O chat sempre tenta recuperar trechos relevantes primeiro (**RAG**). Se n√£o houver LLM, a resposta √© **sint√©tica extrativa**.

## üìö Refer√™ncias (dos arquivos enviados)
- Roteiro: ‚ÄúEstudo de Caso‚Äù„Äê19‚Ä†source„Äë
- Exemplo de PDF: ‚ÄúLei 9.394/1996 (LDB)‚Äù„Äê20‚Ä†source„Äë